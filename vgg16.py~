import os
import json
import numpy as np
import PIL
from PIL import Image

import keras
from keras.utils import Sequence
from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, GlobalAveragePooling2D
from keras.models import Sequential, Model
from keras.utils import Sequence
from keras.optimizers import SGD, Adam
from keras.applications.vgg16 import VGG16, preprocess_input
from keras.callbacks import TensorBoard
tensorboard = TensorBoard(log_dir='logs', histogram_freq=0, write_graph=True, write_images=True)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

os.chdir("/zhome/12/f/134534/Desktop/rico")

batch_size = 16
'''
X_train = []
y_train = []
count = 0
arrows = 0
no_arrows = 0
for i in range(1, 58000):
    path = '/work3/s182091/rico/semantic_annotations/{}.json'.format(i)
    if(os.path.isfile(path)):
        count+=1
        with open(path) as json_file:
            legend = json.load(json_file)
            if('arrow_backward' in str(legend['children'])):
                if(arrows<10000):
                    X_train.append(i)
                    y_train.append(1)
                    arrows += 1
            elif(no_arrows<10000):
                X_train.append(i)
                y_train.append(0)
                no_arrows += 1

#with open('X_train.txt', 'w') as f:
#    for item in X_train:
#        f.write("%s\n" % str(item))

#with open('y_train.txt', 'w') as f:
#    for item in y_train:
#        f.write("%s\n" % str(item))

with open('X_train.txt', 'w') as filehandle:  
    json.dump(X_train, filehandle)
with open('y_train.txt', 'w') as filehandle:  
    json.dump(y_train, filehandle)

print(np.shape(X_train))
print(np.shape(y_train))
print(y_train.count(0))
print(y_train.count(1))
'''
with open('X_train.txt', 'r') as filehandle:  
    X_train = json.load(filehandle)
with open('y_train.txt', 'r') as filehandle:  
    y_train = json.load(filehandle)

class Batch_gen(Sequence):
    def __init__(self, image_filenames, labels, batch_size):
        self.image_filenames, self.labels = image_filenames, labels
        self.batch_size = batch_size

    def __len__(self):
        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]

        return np.array([np.array(Image.open('/work3/s182091/rico/combined/{}.jpg'.format(photo_path)).resize((360, 640)))/255 for photo_path in batch_x]), np.array(batch_y)

y_train = keras.utils.to_categorical(y_train)
train_batchgen = Batch_gen(X_train, y_train, batch_size)


###################################
####     VGG archictecture     ####
###################################

vgg_16_model = VGG16(weights='imagenet', include_top=False, input_shape = (640, 360, 3))

# get layers and add average pooling layer
x = vgg_16_model.output
x = GlobalAveragePooling2D()(x)
#x = Flatten()(x)

# add fully-connected layers
x = Dense(300, activation='relu')(x)
x = Dense(20, activation='relu')(x)

# add output layer
predictions = Dense(2, activation='softmax')(x)

model = Model(inputs=vgg_16_model.input, outputs=predictions)

#for layer in vgg_16_model.layers:
    #layer.trainable = False

print(model.summary())

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8)

model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit_generator(train_batchgen,
              steps_per_epoch=(20000 // batch_size),
              shuffle = True,
              epochs=10,
              use_multiprocessing=True,
              callbacks=[tensorboard])

model.save("models/vgg_16_balanced.h5")

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.savefig("acc2-fine.png")












